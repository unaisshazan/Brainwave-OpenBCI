##Mind-Controlled Tech? My Final-Semester Students Just Made It Happen.

I’m incredibly proud to share the incredible work of my final-semester students from China, who recently completed an advanced internship project 
under my mentorship—developing a real-time brainwave-controlled system using OpenBCI, Python, Arduino, and Machine Learning.

Using the Daisy v3 wireless EEG headset, we captured real-time brain activity, with a focus on alpha and beta waves.

In one session, we recorded signals from a participant named Andy while he focused on a bottle.
➤ Brainwave data was first visualized in real-time frequency graphs using OpenBCI Cyton software

➤ We then applied Fast Fourier Transform (FFT) to analyze signal patterns more deeply

➤ The processed data was streamed into Python and visualized using Matplotlib

➤ Data was stored in a CSV, and Power Spectral Density (PSD) was calculated to identify Andy’s unique alpha and beta ranges

➤ Based on these ranges, commands were sent from Python to an Arduino via serial communication to control an LED


✅ When focused → LED turned ON
❌ When distracted → LED turned OFF

What makes this project even more exciting is its personalization—each user goes through a custom 
calibration process to define their focus thresholds, making this ideal for real-time BCI applications.

From neuro-feedback to brain-controlled robotics, the potential is limitless.

Watching my students bring together neuroscience, software, and embedded systems into a working solution has been one of the most fulfilling experiences of my mentorship journey.

They didn’t just finish their semester with a project.
They finished by creating the future.**
